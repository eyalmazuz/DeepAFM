{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from AFM import AFM, DeepAFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sample(df, columns_unqiue):\n",
    "    x = df.groupby(['userId', 'movieId'])\n",
    "    negative_df = pd.DataFrame()\n",
    "    for name, group in tqdm(x):\n",
    "        for index, row in tqdm(group.iterrows(), leave=False):\n",
    "            tag_options = list(set(columns_unqiue['tag']) - set(group.tag.tolist()))\n",
    "           \n",
    "\n",
    "            negative_row1 = row.copy()\n",
    "            negative_row2 = row.copy()\n",
    "\n",
    "            if tag_options:\n",
    "                new_tag = random.choices(tag_options, k=2)\n",
    "                negative_row1.tag = new_tag[0]\n",
    "                negative_row2.tag = new_tag[1]\n",
    "    \n",
    "            negative_df = negative_df.append(negative_row1)\n",
    "            negative_df = negative_df.append(negative_row2)\n",
    "        \n",
    "    \n",
    "    return negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('movielens_all.csv'):\n",
    "    \n",
    "    movielens_df = pd.read_csv('ml-20m/tags.csv', sep=',')\n",
    "    \n",
    "    columns_unqiue = {}\n",
    "    for column in movielens_df.columns:\n",
    "        columns_unqiue[column] = movielens_df[column].unique().tolist()\n",
    "\n",
    "    \n",
    "    negative_df = negative_sample(movielens_df, columns_unqiue)\n",
    "\n",
    "    negative_df['label'] = [0] * negative_df.shape[0]\n",
    "\n",
    "    negative_df = negative_df[['userId', 'movieId', 'tag']]\n",
    "\n",
    "    movielens_df['label'] = [1] * movielens_df.shape[0]\n",
    "\n",
    "    df = movielens_df.append(negative_df)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.to_csv('movielens_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('movielens_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "df.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124998.0</td>\n",
       "      <td>76251.0</td>\n",
       "      <td>foul language</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131620.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>Sally Field</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121164.0</td>\n",
       "      <td>30848.0</td>\n",
       "      <td>David E. Durston</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91544.0</td>\n",
       "      <td>94466.0</td>\n",
       "      <td>==============</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93258.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>high-tech firms</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396687</th>\n",
       "      <td>33119.0</td>\n",
       "      <td>97938.0</td>\n",
       "      <td>AFI 10 (courtroom drama)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396688</th>\n",
       "      <td>19356.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>prescient</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396689</th>\n",
       "      <td>57124.0</td>\n",
       "      <td>67197.0</td>\n",
       "      <td>watch again before hating</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396690</th>\n",
       "      <td>127138.0</td>\n",
       "      <td>70451.0</td>\n",
       "      <td>add to prospects list</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396691</th>\n",
       "      <td>58612.0</td>\n",
       "      <td>34542.0</td>\n",
       "      <td>Alter ego</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1396692 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId  movieId                        tag  label\n",
       "0        124998.0  76251.0              foul language    1.0\n",
       "1        131620.0   5707.0                Sally Field    1.0\n",
       "2        121164.0  30848.0           David E. Durston    0.0\n",
       "3         91544.0  94466.0             ==============    0.0\n",
       "4         93258.0    924.0            high-tech firms    0.0\n",
       "...           ...      ...                        ...    ...\n",
       "1396687   33119.0  97938.0   AFI 10 (courtroom drama)    0.0\n",
       "1396688   19356.0    593.0                  prescient    0.0\n",
       "1396689   57124.0  67197.0  watch again before hating    0.0\n",
       "1396690  127138.0  70451.0      add to prospects list    1.0\n",
       "1396691   58612.0  34542.0                  Alter ego    0.0\n",
       "\n",
       "[1396692 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label']\n",
    "df.drop(columns=['label'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "for column in df.columns:\n",
    "    encoders[column] = LabelEncoder()\n",
    "    df[column] = encoders[column].fit_transform(df[column].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.nunique().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    \n",
    "    loss = loss_object(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    rmse = tf.math.sqrt(loss)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "afm = AFM(features, embedding_size=256, attention_factor=16, rate=0.1, reg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, labels, test_size=0.1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.BinaryCrossentropy(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "train_auc = tf.keras.metrics.AUC(name='train_auc')\n",
    "\n",
    "val_loss = tf.keras.metrics.BinaryCrossentropy(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "val_auc = tf.keras.metrics.AUC(name='val_auc')\n",
    "\n",
    "test_loss = tf.keras.metrics.BinaryCrossentropy(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
    "test_auc = tf.keras.metrics.AUC(name='test_auc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, target):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions  = afm(inputs, True)\n",
    "        loss = loss_function(y_true=target, y_pred=predictions)\n",
    "                \n",
    "    gradients = tape.gradient(loss, afm.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, afm.trainable_variables))\n",
    "\n",
    "    train_loss(y_true=target, y_pred=predictions)\n",
    "    train_accuracy(y_true=target, y_pred=predictions)\n",
    "    train_auc(y_true=target, y_pred=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "STEPS = x_train.shape[0] // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/ml/AFM\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=afm,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118326</th>\n",
       "      <td>7168</td>\n",
       "      <td>6809</td>\n",
       "      <td>36404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105932</th>\n",
       "      <td>7602</td>\n",
       "      <td>15559</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108919</th>\n",
       "      <td>5791</td>\n",
       "      <td>1033</td>\n",
       "      <td>12634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407713</th>\n",
       "      <td>6560</td>\n",
       "      <td>17891</td>\n",
       "      <td>5715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867650</th>\n",
       "      <td>6833</td>\n",
       "      <td>319</td>\n",
       "      <td>28477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141924</th>\n",
       "      <td>6191</td>\n",
       "      <td>1124</td>\n",
       "      <td>24895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373252</th>\n",
       "      <td>1534</td>\n",
       "      <td>46</td>\n",
       "      <td>27805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75574</th>\n",
       "      <td>960</td>\n",
       "      <td>11577</td>\n",
       "      <td>10007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342824</th>\n",
       "      <td>6943</td>\n",
       "      <td>13810</td>\n",
       "      <td>33387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053601</th>\n",
       "      <td>54</td>\n",
       "      <td>252</td>\n",
       "      <td>31337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId    tag\n",
       "1118326    7168     6809  36404\n",
       "1105932    7602    15559  24884\n",
       "1108919    5791     1033  12634\n",
       "407713     6560    17891   5715\n",
       "867650     6833      319  28477\n",
       "...         ...      ...    ...\n",
       "1141924    6191     1124  24895\n",
       "373252     1534       46  27805\n",
       "75574       960    11577  10007\n",
       "342824     6943    13810  33387\n",
       "1053601      54      252  31337\n",
       "\n",
       "[1005617 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.6913 Accuracy 0.5156 AUC 0.5535\n",
      "Epoch 1 Batch 2500 Loss 0.6498 Accuracy 0.6509 AUC 0.5103\n",
      "Epoch 1 Batch 5000 Loss 0.6445 Accuracy 0.6545 AUC 0.5230\n",
      "Epoch 1 Batch 7500 Loss 0.6420 Accuracy 0.6562 AUC 0.5364\n",
      "\n",
      "Validation Loss 0.6319 Accuracy 0.6664 AUC 0.6086\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.6533 Accuracy 0.6328 AUC 0.5782\n",
      "Epoch 2 Batch 2500 Loss 0.6361 Accuracy 0.6602 AUC 0.5979\n",
      "Epoch 2 Batch 5000 Loss 0.6352 Accuracy 0.6607 AUC 0.6063\n",
      "Epoch 2 Batch 7500 Loss 0.6341 Accuracy 0.6616 AUC 0.6132\n",
      "\n",
      "Validation Loss 0.6269 Accuracy 0.6660 AUC 0.6608\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.6392 Accuracy 0.6641 AUC 0.5418\n",
      "Epoch 3 Batch 2500 Loss 0.6305 Accuracy 0.6648 AUC 0.6397\n",
      "Epoch 3 Batch 5000 Loss 0.6295 Accuracy 0.6655 AUC 0.6432\n",
      "Epoch 3 Batch 7500 Loss 0.6286 Accuracy 0.6660 AUC 0.6474\n",
      "\n",
      "Validation Loss 0.6221 Accuracy 0.6660 AUC 0.6935\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.6400 Accuracy 0.6484 AUC 0.6939\n",
      "Epoch 4 Batch 2500 Loss 0.6268 Accuracy 0.6658 AUC 0.6611\n",
      "Epoch 4 Batch 5000 Loss 0.6252 Accuracy 0.6670 AUC 0.6658\n",
      "Epoch 4 Batch 7500 Loss 0.6243 Accuracy 0.6678 AUC 0.6686\n",
      "\n",
      "Validation Loss 0.6172 Accuracy 0.6684 AUC 0.7132\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.5817 Accuracy 0.7578 AUC 0.7325\n",
      "Epoch 5 Batch 2500 Loss 0.6217 Accuracy 0.6690 AUC 0.6795\n",
      "Epoch 5 Batch 5000 Loss 0.6207 Accuracy 0.6700 AUC 0.6824\n",
      "Epoch 5 Batch 7500 Loss 0.6198 Accuracy 0.6711 AUC 0.6856\n",
      "\n",
      "Validation Loss 0.6137 Accuracy 0.6727 AUC 0.7297\n",
      "\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/ml/AFM/ckpt-1\n",
      "Epoch 5 Loss 0.6197 Accuracy 0.6713\n",
      "Time taken for 1 epoch: 353.8055295944214 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_auc.reset_states()\n",
    "\n",
    "    \n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    val_auc.reset_states()\n",
    "\n",
    "    for batch in range(STEPS):\n",
    "        \n",
    "        sample = x_train.sample(n=BATCH_SIZE)\n",
    "        indexs = sample.index\n",
    "        y = y_train[indexs].values.reshape((-1,1))\n",
    "        x = {k: np.array(list(v.values())) for k, v in sample.to_dict().items()}\n",
    "        train_step(x, y)\n",
    "\n",
    "        if batch % 2500 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result(), train_auc.result()))\n",
    "\n",
    "    for batch in range(x_val.shape[0] // BATCH_SIZE):\n",
    "\n",
    "        sample = x_val.sample(n=BATCH_SIZE)\n",
    "        indexs = sample.index\n",
    "        y = y_val[indexs].values.reshape((-1,1))\n",
    "        x = {k: np.array(list(v.values())) for k, v in sample.to_dict().items()}\n",
    "        val_predictions = afm(x, False)\n",
    "\n",
    "        val_loss(y_true=y, y_pred=val_predictions)\n",
    "        val_accuracy(y_true=y, y_pred=val_predictions)\n",
    "        val_auc(y_true=y, y_pred=val_predictions)\n",
    "\n",
    "    print()\n",
    "    print('Validation Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n",
    "      val_loss.result(), val_accuracy.result(), val_auc.result()))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "        print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                    train_loss.result(), \n",
    "                                                    train_accuracy.result()))\n",
    "\n",
    "        print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.6136 Accuracy 0.6735 AUC 0.7270\n"
     ]
    }
   ],
   "source": [
    "test_loss.reset_states()\n",
    "test_accuracy.reset_states()\n",
    "test_auc.reset_states()\n",
    "\n",
    "for batch in range(x_test.shape[0] // BATCH_SIZE):\n",
    "\n",
    "        sample = x_test.sample(n=BATCH_SIZE)\n",
    "        indexs = sample.index\n",
    "        y = y_test[indexs].values.reshape((-1,1))\n",
    "        x = {k: np.array(list(v.values())) for k, v in sample.to_dict().items()}\n",
    "        test_predictions = afm(x, False)\n",
    "\n",
    "        test_loss(y_true=y, y_pred=test_predictions)\n",
    "        test_accuracy(y_true=y, y_pred=test_predictions)\n",
    "        test_auc(y_true=y, y_pred=test_predictions)\n",
    "\n",
    "print('Test Loss {:.4f} Accuracy {:.4f} AUC {:.4f}'.format(\n",
    "      test_loss.result(), test_accuracy.result(), test_auc.result()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
